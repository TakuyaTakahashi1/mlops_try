
name: "A11: scheduled scrape & PR"

on:
  schedule:
    - cron: '0 0 * * *'   # JST 09:00
  workflow_dispatch: {}

permissions:
  contents: write
  pull-requests: write

concurrency:
  group: a11-scrape
  cancel-in-progress: false

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: pip

      - name: Install deps
        run: pip install -r requirements.txt

      - name: Create .env for script/tests
        run: |
          cat > .env <<'ENV'
          DB_URL=postgresql://example
          API_KEY=secret
          ENV

      - name: Run scraper
        run: python automation/scrape_titles.py

      - name: Upload CSV artifact (for debugging)
        uses: actions/upload-artifact@v4
        with:
          name: scraped-csv
          if-no-files-found: ignore
          path: |
            data/titles.csv
            data/daily/*.csv

      - name: Create PR with changes
        uses: peter-evans/create-pull-request@v6
        with:
          branch: chore/daily-scrape
          commit-message: "chore(data): daily scrape"
          title: "A11: daily scrape (data/titles.csv)"
          body: |
            ## Summary
            毎日 09:00 JST に `automation/scrape_titles.py` を実行し、結果をコミットして本PR（固定ブランチ `chore/daily-scrape`）を更新します。

            ## Changes
            - `data/daily/titles-YYYYMMDD.csv` を追加
            - `data/titles.csv` にマージ（重複除去）

            ## Why
            データセットを自動で新鮮に保つため（手動更新を排除）。

            ## How to verify
            - このPRに本日分のCSVが含まれていること
            - Checks（lint, mypy, test 3.11/3.12）が緑であること

            ## Notes
            - ラベル: `automation`, `data`
            - 既存のPRがある場合は更新（新規作成しない）仕様
          labels: data, automation
          delete-branch: true
